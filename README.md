# Building Backpropagation and Neural Networks from Scratch

This notebook has two main goals:

1. **Implement backpropagation from scratch:** Build an automatic differentiation system that computes gradients automaticallyâ€”the core mechanism behind all modern deep learning frameworks.

2. **Implement a Multi-Layer Perceptron (MLP) from scratch:** Build the fundamental components of neural networks (neurons, layers, and complete networks) and understand how they connect together.

Together, these two systems form a complete deep learning framework. At the end, we'll verify everything works by training our MLP on a simple prediction task.

**Note:** This is in DRAFT phase right now. Learn at your will and risk.
